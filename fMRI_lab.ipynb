{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Neuroimaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by Daria Zotova and Elizaveta Genke  \n",
    "Code used: http://nilearn.github.io/index.html  \n",
    "Before starting the tutorial run \"pip install -r requirements.txt\" in the folder with downloaded repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.plotting import show\n",
    "from nilearn import plotting\n",
    "from nilearn.input_data import NiftiMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataset from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/ZOTOVA/ERASMUS/3RD SEMESTER/eHealth/Student Lab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haxby_dataset = datasets.fetch_haxby(data_dir = path,fetch_stimuli=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haxby_dataset = datasets.fetch_haxby(subjects=[], fetch_stimuli=True)\n",
    "stimulus_information = haxby_dataset.stimuli\n",
    "# Show cats\n",
    "plt.figure()\n",
    "for i in range(48):\n",
    "    plt.subplot(6, 8, i + 1)\n",
    "    plt.imshow(imread(stimulus_information['cats'][i]), cmap=plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle('Cats')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show faces\n",
    "plt.figure()\n",
    "for i in range(48):\n",
    "    plt.subplot(6, 8, i + 1)\n",
    "    plt.imshow(imread(stimulus_information['faces'][i]), cmap=plt.cm.gray)\n",
    "    plt.axis(\"off\")\n",
    "    plt.suptitle('Faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply ROI mask provided to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_filename = haxby_dataset.func[0]\n",
    "\n",
    "# Convert the fMRI volume's to a data matrix\n",
    "# The mask is a mask of the Ventral Temporal streaming coming from the\n",
    "# Haxby study:\n",
    "mask_filename = haxby_dataset.mask_vt[0]\n",
    "\n",
    "# Visualize it, using the subject's anatomical image as a\n",
    "# background\n",
    "\n",
    "plotting.plot_roi(mask_filename, bg_img=haxby_dataset.anat[0],\n",
    "                 cmap='Paired')\n",
    "print(fmri_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract fMRI data on a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"NiftiMasker\" to extract the fMRI data on a mask and convert it to data series.\n",
    "masker = NiftiMasker(mask_img=mask_filename, standardize=True)\n",
    "\n",
    "# We give the masker a filename and retrieve a 2D array ready\n",
    "# for machine learning with scikit-learn\n",
    "fmri_masked = masker.fit_transform(fmri_filename)\n",
    "\n",
    "# The shape of \"fmri_masked\" array corresponds to the number of time-points times the number of\n",
    "# voxels in the mask\n",
    "print(\"Shape of an array: \", fmri_masked.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict the analysis to cats and faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the behavioral information stored in a CSV file\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "\n",
    "# Retrieve the experimental conditions (labels), that are prediction targets in the decoding\n",
    "labels_all = behavioral['labels']\n",
    "\n",
    "# Keep only the data corresponding to faces oand cats\n",
    "labels_mask = labels_all.isin(['face', 'cat'])\n",
    "\n",
    "# Apply this mask in the sampe direction to restrict the\n",
    "# classification to the face vs cat discrimination\n",
    "fmri_masked = fmri_masked[labels_mask]\n",
    "# We now have less samples\n",
    "print(fmri_masked.shape)\n",
    "\n",
    "# Apply the same mask to the targets\n",
    "labels = labels_all[labels_mask]\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict targets using Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually split data into training and test sets\n",
    "# Choose how many examples you want to put for the training set and put the rest for the test set\n",
    "\n",
    "X_train = fmri_masked[]\n",
    "Y_train = labels[]\n",
    "X_test = fmri_masked[]\n",
    "Y_test = labels[]\n",
    "\n",
    "# Train the model\n",
    "svc.fit(X_train,Y_train)\n",
    "\n",
    "# Test the model\n",
    "prediction = svc.predict(X_test)\n",
    "# Compute accuracy of SVC classifier\n",
    "accuracy = \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the solution uncomment the line below\n",
    "#%load .\\solutions\\solution1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to use other types of kernels for SVC and explore if it improves results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='')\n",
    "\n",
    "X_train = fmri_masked[]\n",
    "Y_train = labels[]\n",
    "X_test = fmri_masked[]\n",
    "Y_test = labels[]\n",
    "\n",
    "# Train the model\n",
    "svc.fit(X_train,Y_train)\n",
    "\n",
    "# Test the model\n",
    "prediction = svc.predict(X_test)\n",
    "# Compute accuracy of SVC classifier\n",
    "accuracy = \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the solution uncomment the line below\n",
    "#%load .\\solutions\\solution2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with \"KFold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can split the data in train and test set repetitively in a \"KFold\" strategy:\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "# The \"cv\" object's split method can now accept data and create a\n",
    "# generator which can yield the splits.\n",
    "for train, test in cv.split(X=fmri_masked):\n",
    "    labels_masked = labels.values[train]\n",
    "    svc.fit(fmri_masked[train], labels_masked)\n",
    "    prediction = svc.predict(fmri_masked[test])\n",
    "    print((prediction == labels.values[test]).sum()\n",
    "           / float(len(labels.values[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn has tools to perform cross-validation in one line.\n",
    "# Explore \"cross_val_score\" function and evaluate a score by cross-validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "#cv_score = cross_val_score(svc, fmri_masked, labels)\n",
    "cv_score =\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the solution uncomment the line below\n",
    "#%load .\\solutions\\solution3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform classification by using Logistic Regression classifier.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Try to use it with default parameters \n",
    "logistic_cv = \n",
    "\n",
    "# Train the model\n",
    "logistic_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Test the model\n",
    "prediction = logistic_cv.predict(X_test)\n",
    "# Compute accuracy of Logistic Regression classifier\n",
    "accuracy = \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the solution uncomment the line below\n",
    "#%load .\\solutions\\solution4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation from scikit-learn and compute scores\n",
    "log_cv_score = \n",
    "print(log_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the solution uncomment the line below\n",
    "#%load .\\solutions\\solution5.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
